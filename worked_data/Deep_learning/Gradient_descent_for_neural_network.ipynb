{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import tensorflow as tf \n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"Insurance.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>affordibility</th>\n",
       "      <th>have_insurance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>52</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>46</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  affordibility  have_insurance\n",
       "0   22              1               0\n",
       "1   25              0               0\n",
       "2   47              1               1\n",
       "3   52              0               0\n",
       "4   46              1               1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test=train_test_split(df[['age','affordibility']],df.have_insurance,test_size=.2,random_state=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_scaled=x_train.copy()\n",
    "x_train_scaled['age']=x_train_scaled['age']/100\n",
    "\n",
    "x_test_scaled=x_test.copy()\n",
    "x_test_scaled['age']=x_test_scaled['age']/100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>affordibility</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.22</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.29</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.55</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.58</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     age  affordibility\n",
       "0   0.22              1\n",
       "13  0.29              0\n",
       "6   0.55              0\n",
       "17  0.58              1\n",
       "24  0.50              1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_scaled.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "1/1 [==============================] - 0s 419ms/step - loss: 0.6347 - accuracy: 0.5909\n",
      "Epoch 2/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6345 - accuracy: 0.5909\n",
      "Epoch 3/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6342 - accuracy: 0.5909\n",
      "Epoch 4/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6340 - accuracy: 0.5909\n",
      "Epoch 5/200\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.6338 - accuracy: 0.5909\n",
      "Epoch 6/200\n",
      "1/1 [==============================] - 0s 963us/step - loss: 0.6336 - accuracy: 0.5909\n",
      "Epoch 7/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6334 - accuracy: 0.5909\n",
      "Epoch 8/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6332 - accuracy: 0.5909\n",
      "Epoch 9/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6330 - accuracy: 0.5909\n",
      "Epoch 10/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6328 - accuracy: 0.5909\n",
      "Epoch 11/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6326 - accuracy: 0.5909\n",
      "Epoch 12/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6324 - accuracy: 0.5909\n",
      "Epoch 13/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6322 - accuracy: 0.5909\n",
      "Epoch 14/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6320 - accuracy: 0.5909\n",
      "Epoch 15/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6318 - accuracy: 0.5909\n",
      "Epoch 16/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6316 - accuracy: 0.5909\n",
      "Epoch 17/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6314 - accuracy: 0.5909\n",
      "Epoch 18/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6312 - accuracy: 0.5909\n",
      "Epoch 19/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6310 - accuracy: 0.5909\n",
      "Epoch 20/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6308 - accuracy: 0.5909\n",
      "Epoch 21/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6306 - accuracy: 0.5909\n",
      "Epoch 22/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6305 - accuracy: 0.5909\n",
      "Epoch 23/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6303 - accuracy: 0.5909\n",
      "Epoch 24/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6301 - accuracy: 0.5909\n",
      "Epoch 25/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6299 - accuracy: 0.5909\n",
      "Epoch 26/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6297 - accuracy: 0.5909\n",
      "Epoch 27/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6295 - accuracy: 0.5909\n",
      "Epoch 28/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6293 - accuracy: 0.5909\n",
      "Epoch 29/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6291 - accuracy: 0.5909\n",
      "Epoch 30/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6290 - accuracy: 0.5909\n",
      "Epoch 31/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6288 - accuracy: 0.5909\n",
      "Epoch 32/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6286 - accuracy: 0.5909\n",
      "Epoch 33/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6284 - accuracy: 0.5909\n",
      "Epoch 34/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6282 - accuracy: 0.5909\n",
      "Epoch 35/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6281 - accuracy: 0.5909\n",
      "Epoch 36/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6279 - accuracy: 0.5909\n",
      "Epoch 37/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6277 - accuracy: 0.5909\n",
      "Epoch 38/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6275 - accuracy: 0.5909\n",
      "Epoch 39/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6274 - accuracy: 0.5909\n",
      "Epoch 40/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6272 - accuracy: 0.5909\n",
      "Epoch 41/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6270 - accuracy: 0.5909\n",
      "Epoch 42/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6268 - accuracy: 0.5909\n",
      "Epoch 43/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6267 - accuracy: 0.5909\n",
      "Epoch 44/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6265 - accuracy: 0.5909\n",
      "Epoch 45/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6263 - accuracy: 0.5909\n",
      "Epoch 46/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6262 - accuracy: 0.5909\n",
      "Epoch 47/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6260 - accuracy: 0.5909\n",
      "Epoch 48/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6258 - accuracy: 0.5909\n",
      "Epoch 49/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6257 - accuracy: 0.5909\n",
      "Epoch 50/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6255 - accuracy: 0.5909\n",
      "Epoch 51/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6254 - accuracy: 0.5909\n",
      "Epoch 52/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6252 - accuracy: 0.5909\n",
      "Epoch 53/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6250 - accuracy: 0.5909\n",
      "Epoch 54/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6249 - accuracy: 0.5909\n",
      "Epoch 55/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6247 - accuracy: 0.5909\n",
      "Epoch 56/200\n",
      "1/1 [==============================] - 0s 994us/step - loss: 0.6246 - accuracy: 0.5909\n",
      "Epoch 57/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6244 - accuracy: 0.5909\n",
      "Epoch 58/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6242 - accuracy: 0.5909\n",
      "Epoch 59/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6241 - accuracy: 0.5909\n",
      "Epoch 60/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6239 - accuracy: 0.5909\n",
      "Epoch 61/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6238 - accuracy: 0.5909\n",
      "Epoch 62/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6236 - accuracy: 0.5909\n",
      "Epoch 63/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6235 - accuracy: 0.5909\n",
      "Epoch 64/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6233 - accuracy: 0.5909\n",
      "Epoch 65/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6232 - accuracy: 0.5909\n",
      "Epoch 66/200\n",
      "1/1 [==============================] - 0s 992us/step - loss: 0.6230 - accuracy: 0.5909\n",
      "Epoch 67/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6229 - accuracy: 0.5909\n",
      "Epoch 68/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6228 - accuracy: 0.5909\n",
      "Epoch 69/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6226 - accuracy: 0.5909\n",
      "Epoch 70/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6225 - accuracy: 0.5909\n",
      "Epoch 71/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6223 - accuracy: 0.5909\n",
      "Epoch 72/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6222 - accuracy: 0.5909\n",
      "Epoch 73/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6220 - accuracy: 0.5909\n",
      "Epoch 74/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6219 - accuracy: 0.5909\n",
      "Epoch 75/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6218 - accuracy: 0.5909\n",
      "Epoch 76/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6216 - accuracy: 0.5909\n",
      "Epoch 77/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6215 - accuracy: 0.5909\n",
      "Epoch 78/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6214 - accuracy: 0.5909\n",
      "Epoch 79/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6212 - accuracy: 0.5909\n",
      "Epoch 80/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6211 - accuracy: 0.5909\n",
      "Epoch 81/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6209 - accuracy: 0.5909\n",
      "Epoch 82/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6208 - accuracy: 0.5909\n",
      "Epoch 83/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6207 - accuracy: 0.5909\n",
      "Epoch 84/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6206 - accuracy: 0.5909\n",
      "Epoch 85/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6204 - accuracy: 0.5909\n",
      "Epoch 86/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6203 - accuracy: 0.5909\n",
      "Epoch 87/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6202 - accuracy: 0.5909\n",
      "Epoch 88/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6200 - accuracy: 0.5909\n",
      "Epoch 89/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6199 - accuracy: 0.5909\n",
      "Epoch 90/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6198 - accuracy: 0.5909\n",
      "Epoch 91/200\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.6197 - accuracy: 0.5909\n",
      "Epoch 92/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6195 - accuracy: 0.5909\n",
      "Epoch 93/200\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.6194 - accuracy: 0.5909\n",
      "Epoch 94/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6193 - accuracy: 0.5909\n",
      "Epoch 95/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6192 - accuracy: 0.5909\n",
      "Epoch 96/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6191 - accuracy: 0.5909\n",
      "Epoch 97/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6189 - accuracy: 0.5909\n",
      "Epoch 98/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6188 - accuracy: 0.5909\n",
      "Epoch 99/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6187 - accuracy: 0.5909\n",
      "Epoch 100/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6186 - accuracy: 0.5909\n",
      "Epoch 101/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6185 - accuracy: 0.5909\n",
      "Epoch 102/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6183 - accuracy: 0.5909\n",
      "Epoch 103/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6182 - accuracy: 0.5909\n",
      "Epoch 104/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6181 - accuracy: 0.5909\n",
      "Epoch 105/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6180 - accuracy: 0.5909\n",
      "Epoch 106/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6179 - accuracy: 0.5909\n",
      "Epoch 107/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6178 - accuracy: 0.5909\n",
      "Epoch 108/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6177 - accuracy: 0.5909\n",
      "Epoch 109/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6176 - accuracy: 0.5909\n",
      "Epoch 110/200\n",
      "1/1 [==============================] - 0s 996us/step - loss: 0.6174 - accuracy: 0.5909\n",
      "Epoch 111/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6173 - accuracy: 0.5909\n",
      "Epoch 112/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6172 - accuracy: 0.5909\n",
      "Epoch 113/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6171 - accuracy: 0.5909\n",
      "Epoch 114/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6170 - accuracy: 0.5909\n",
      "Epoch 115/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6169 - accuracy: 0.5909\n",
      "Epoch 116/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6168 - accuracy: 0.5909\n",
      "Epoch 117/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6167 - accuracy: 0.5909\n",
      "Epoch 118/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6166 - accuracy: 0.5909\n",
      "Epoch 119/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6165 - accuracy: 0.5909\n",
      "Epoch 120/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6164 - accuracy: 0.5909\n",
      "Epoch 121/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6163 - accuracy: 0.5909\n",
      "Epoch 122/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6162 - accuracy: 0.5909\n",
      "Epoch 123/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6161 - accuracy: 0.5909\n",
      "Epoch 124/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6160 - accuracy: 0.5909\n",
      "Epoch 125/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6159 - accuracy: 0.5909\n",
      "Epoch 126/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6158 - accuracy: 0.5909\n",
      "Epoch 127/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6157 - accuracy: 0.5909\n",
      "Epoch 128/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6156 - accuracy: 0.5909\n",
      "Epoch 129/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6155 - accuracy: 0.5909\n",
      "Epoch 130/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6154 - accuracy: 0.5909\n",
      "Epoch 131/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6153 - accuracy: 0.5909\n",
      "Epoch 132/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6152 - accuracy: 0.5909\n",
      "Epoch 133/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6151 - accuracy: 0.5909\n",
      "Epoch 134/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6150 - accuracy: 0.5909\n",
      "Epoch 135/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6149 - accuracy: 0.5909\n",
      "Epoch 136/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6148 - accuracy: 0.5909\n",
      "Epoch 137/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6147 - accuracy: 0.5909\n",
      "Epoch 138/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6146 - accuracy: 0.5909\n",
      "Epoch 139/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6146 - accuracy: 0.5909\n",
      "Epoch 140/200\n",
      "1/1 [==============================] - 0s 971us/step - loss: 0.6145 - accuracy: 0.5909\n",
      "Epoch 141/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6144 - accuracy: 0.5909\n",
      "Epoch 142/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6143 - accuracy: 0.5909\n",
      "Epoch 143/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6142 - accuracy: 0.5909\n",
      "Epoch 144/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6141 - accuracy: 0.5909\n",
      "Epoch 145/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6140 - accuracy: 0.5909\n",
      "Epoch 146/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6139 - accuracy: 0.5909\n",
      "Epoch 147/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6138 - accuracy: 0.5909\n",
      "Epoch 148/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6138 - accuracy: 0.5909\n",
      "Epoch 149/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6137 - accuracy: 0.5909\n",
      "Epoch 150/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6136 - accuracy: 0.5909\n",
      "Epoch 151/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6135 - accuracy: 0.5909\n",
      "Epoch 152/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6134 - accuracy: 0.5909\n",
      "Epoch 153/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6133 - accuracy: 0.5909\n",
      "Epoch 154/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6133 - accuracy: 0.5909\n",
      "Epoch 155/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6132 - accuracy: 0.5909\n",
      "Epoch 156/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6131 - accuracy: 0.5909\n",
      "Epoch 157/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6130 - accuracy: 0.5909\n",
      "Epoch 158/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6129 - accuracy: 0.5909\n",
      "Epoch 159/200\n",
      "1/1 [==============================] - 0s 995us/step - loss: 0.6128 - accuracy: 0.5909\n",
      "Epoch 160/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6128 - accuracy: 0.5909\n",
      "Epoch 161/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6127 - accuracy: 0.5909\n",
      "Epoch 162/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6126 - accuracy: 0.5909\n",
      "Epoch 163/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6125 - accuracy: 0.5909\n",
      "Epoch 164/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6124 - accuracy: 0.5909\n",
      "Epoch 165/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6124 - accuracy: 0.5909\n",
      "Epoch 166/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6123 - accuracy: 0.5909\n",
      "Epoch 167/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6122 - accuracy: 0.5909\n",
      "Epoch 168/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6121 - accuracy: 0.5909\n",
      "Epoch 169/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6121 - accuracy: 0.5909\n",
      "Epoch 170/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6120 - accuracy: 0.5909\n",
      "Epoch 171/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6119 - accuracy: 0.5909\n",
      "Epoch 172/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6118 - accuracy: 0.5909\n",
      "Epoch 173/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6118 - accuracy: 0.5909\n",
      "Epoch 174/200\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.6117 - accuracy: 0.5909\n",
      "Epoch 175/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6116 - accuracy: 0.5909\n",
      "Epoch 176/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6115 - accuracy: 0.5909\n",
      "Epoch 177/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6115 - accuracy: 0.5909\n",
      "Epoch 178/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6114 - accuracy: 0.5909\n",
      "Epoch 179/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6113 - accuracy: 0.5909\n",
      "Epoch 180/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6112 - accuracy: 0.5909\n",
      "Epoch 181/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6112 - accuracy: 0.5909\n",
      "Epoch 182/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6111 - accuracy: 0.5909\n",
      "Epoch 183/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6110 - accuracy: 0.5909\n",
      "Epoch 184/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6109 - accuracy: 0.5909\n",
      "Epoch 185/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6109 - accuracy: 0.5909\n",
      "Epoch 186/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6108 - accuracy: 0.5909\n",
      "Epoch 187/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6107 - accuracy: 0.5909\n",
      "Epoch 188/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6107 - accuracy: 0.5909\n",
      "Epoch 189/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6106 - accuracy: 0.5909\n",
      "Epoch 190/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6105 - accuracy: 0.5909\n",
      "Epoch 191/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6105 - accuracy: 0.5909\n",
      "Epoch 192/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6104 - accuracy: 0.5909\n",
      "Epoch 193/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6103 - accuracy: 0.5909\n",
      "Epoch 194/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6102 - accuracy: 0.5909\n",
      "Epoch 195/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6102 - accuracy: 0.5909\n",
      "Epoch 196/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6101 - accuracy: 0.5909\n",
      "Epoch 197/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6100 - accuracy: 0.5909\n",
      "Epoch 198/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6100 - accuracy: 0.6364\n",
      "Epoch 199/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6099 - accuracy: 0.6364\n",
      "Epoch 200/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6098 - accuracy: 0.6364\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1c4e234d390>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=keras.Sequential([\n",
    "    keras.layers.Dense(1,input_shape=(2,),activation='sigmoid',kernel_initializer='ones',bias_initializer='zeros')\n",
    "])\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy'])\n",
    "model.fit(x_train_scaled,y_train,epochs=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 113ms/step - loss: 0.6677 - accuracy: 0.5000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6676662564277649, 0.5]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test_scaled,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>affordibility</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.47</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.18</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.26</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.28</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.49</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.61</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     age  affordibility\n",
       "2   0.47              1\n",
       "10  0.18              1\n",
       "21  0.26              0\n",
       "11  0.28              1\n",
       "14  0.49              1\n",
       "9   0.61              1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.7502942 ],\n",
       "       [0.69726974],\n",
       "       [0.5154766 ],\n",
       "       [0.7162637 ],\n",
       "       [0.7537135 ],\n",
       "       [0.77356017]], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(x_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.91673   ],\n",
       "        [0.84574246]], dtype=float32),\n",
       " array([-0.17642361], dtype=float32))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coef,intercept=model.get_weights()\n",
    "coef,intercept"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check in python code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9999999847700205"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "def sigmoid(x):\n",
    "    return 1/(1+math.exp(-x))\n",
    "sigmoid(18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction_function(age, affordibility):\n",
    "    weighted_sum = coef[0]*age + coef[1]*affordibility + intercept\n",
    "    return sigmoid(weighted_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9999999999429772"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_function(25,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_function(56,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_loss(y_real,y_predicted):\n",
    "    epsilon=1e-15\n",
    "    y_predicted_new=[max(i,epsilon) for i in y_predicted]\n",
    "    y_predicted_new=[min(i,1-epsilon) for i in y_predicted_new]\n",
    "    y_predicted_new=np.array(y_predicted_new)\n",
    "    return -np.mean(y_real*np.log(y_predicted_new)+(1-y_real)*np.log(1-y_predicted_new)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.99999386, 0.5       , 0.73105858])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def sigmoid_numpy(x):\n",
    "    return (1/(1+np.exp(-x)))\n",
    "sigmoid_numpy= np.vectorize(sigmoid_numpy)\n",
    "sigmoid_numpy(np.array([12,0,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grediant_descent(age, affordibility,y_real,epochs):\n",
    "    w1=w2=1 #this is random\n",
    "    bias=0 # this is random\n",
    "    rate=0.5 # this is radom\n",
    "    n= len(age)\n",
    "    for i  in range(epochs):\n",
    "        weighted_sum = w1*age + w2*affordibility +bias\n",
    "        y_predicted = sigmoid_numpy(weighted_sum)\n",
    "        loss= log_loss(y_real,y_predicted)\n",
    "        w1d= (1/n)*np.dot(np.transpose(age),(y_predicted-y_real))\n",
    "        w2d= (1/n)*np.dot(np.transpose(affordibility),(y_predicted-y_real))\n",
    "        bias_d=np.mean(y_predicted-y_real)\n",
    "        w1=w1-rate*w1d\n",
    "        w2=w2-rate*w2d\n",
    "        print(f\"Epoch{epochs}, w1{w1}, w2{w2}, Bias{bias}, Loss{loss}\")\n",
    "    return w1,w2,bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch250, w10.9907935440408127, w20.9718534166129719, Bias0, Loss0.6346629803353081\n",
      "Epoch250, w10.9822988457688695, w20.9453180752475226, Bias0, Loss0.6329607413873718\n",
      "Epoch250, w10.9744842020227098, w20.9203261765063466, Bias0, Loss0.6314547683088135\n",
      "Epoch250, w10.967317663085986, w20.8968090220823797, Bias0, Loss0.6301252485169614\n",
      "Epoch250, w10.9607672897186681, w20.8746976242560986, Bias0, Loss0.6289537979728407\n",
      "Epoch250, w10.9548013819425827, w20.8539232494460756, Bias0, Loss0.6279234698764314\n",
      "Epoch250, w10.9493886790741844, w20.8344178946729324, Bias0, Loss0.6270187364561268\n",
      "Epoch250, w10.9444985313445382, w20.8161146977680993, Bias0, Loss0.6262254490799323\n",
      "Epoch250, w10.9401010441175228, w20.7989482837140448, Bias0, Loss0.6255307816021958\n",
      "Epoch250, w10.9361671962217425, w20.7828550506667349, Bias0, Loss0.6249231614061426\n",
      "Epoch250, w10.9326689342656443, w20.767773400023627, Bias0, Loss0.6243921920673453\n",
      "Epoch250, w10.9295792450287672, w20.7536439154092989, Bias0, Loss0.6239285709940017\n",
      "Epoch250, w10.9268722081362244, w20.7404094957065682, Bias0, Loss0.6235240048331353\n",
      "Epoch250, w10.924523031249592, w20.7280154473134594, Bias0, Loss0.6231711248938727\n",
      "Epoch250, w10.9225080699650738, w20.7164095407018166, Bias0, Loss0.6228634043471035\n",
      "Epoch250, w10.92080483451681, w20.7055420361328845, Bias0, Loss0.6225950785249798\n",
      "Epoch250, w10.9193919852547041, w20.6953656830840163, Bias0, Loss0.6223610692679536\n",
      "Epoch250, w10.9182493187148537, w20.6858356975881301, Bias0, Loss0.6221569139512296\n",
      "Epoch250, w10.9173577459368346, w20.6769097213071712, Bias0, Loss0.6219786995634977\n",
      "Epoch250, w10.9166992645137529, w20.6685477657710531, Bias0, Loss0.6218230020036791\n",
      "Epoch250, w10.9162569256942047, w20.6607121448281867, Bias0, Loss0.6216868306001913\n",
      "Epoch250, w10.9160147976945002, w20.6533673979827832, Bias0, Loss0.6215675777356198\n",
      "Epoch250, w10.9159579262277551, w20.6464802069444886, Bias0, Loss0.6214629733714507\n",
      "Epoch250, w10.9160722931156571, w20.6400193073918948, Bias0, Loss0.6213710442067817\n",
      "Epoch250, w10.9163447737199681, w20.6339553976554283, Bias0, Loss0.621290077166451\n",
      "Epoch250, w10.9167630938145124, w20.628261045757879, Bias0, Loss0.6212185868930806\n",
      "Epoch250, w10.9173157864144683, w20.622910596012153, Bias0, Loss0.6211552869101363\n",
      "Epoch250, w10.9179921489877966, w20.6178800761646686, Bias0, Loss0.6210990641259077\n",
      "Epoch250, w10.918782201392937, w20.6131471058876083, Bias0, Loss0.6210489563584827\n",
      "Epoch250, w10.9196766448167008, w20.6086908072621167, Bias0, Loss0.6210041325771234\n",
      "Epoch250, w10.9206668219256788, w20.6044917177554237, Bias0, Loss0.6209638755741058\n",
      "Epoch250, w10.9217446783925758, w20.6005317060756974, Bias0, Loss0.6209275668017112\n",
      "Epoch250, w10.9229027259147613, w20.5967938911870728, Bias0, Loss0.6208946731305324\n",
      "Epoch250, w10.9241340068051305, w20.5932625646817857, Bias0, Loss0.6208647353068245\n",
      "Epoch250, w10.925432060204265, w20.5899231166347635, Bias0, Loss0.620837357907695\n",
      "Epoch250, w10.9267908899371229, w20.5867619650066458, Bias0, Loss0.6208122006130703\n",
      "Epoch250, w10.9282049340163612, w20.5837664886124285, Bias0, Loss0.6207889706323777\n",
      "Epoch250, w10.92966903577728, w20.580924963633302, Bias0, Loss0.6207674161415205\n",
      "Epoch250, w10.9311784166157008, w20.5782265036174951, Bias0, Loss0.6207473206019919\n",
      "Epoch250, w10.9327286502893555, w20.5756610028908896, Bias0, Loss0.6207284978487896\n",
      "Epoch250, w10.9343156387351216, w20.5732190832788242, Bias0, Loss0.6207107878472337\n",
      "Epoch250, w10.9359355893482941, w20.5708920440259658, Bias0, Loss0.6206940530308764\n",
      "Epoch250, w10.9375849936657107, w20.5686718147906243, Bias0, Loss0.6206781751435109\n",
      "Epoch250, w10.9392606073916313, w20.5665509115827374, Bias0, Loss0.6206630525179427\n",
      "Epoch250, w10.9409594317035743, w20.5645223955103862, Bias0, Loss0.6206485977327303\n",
      "Epoch250, w10.9426786957746001, w20.5625798341976119, Bias0, Loss0.6206347355956752\n",
      "Epoch250, w10.9444158404486293, w20.5607172657360628, Bias0, Loss0.6206214014095089\n",
      "Epoch250, w10.9461685030061185, w20.5589291650342493, Bias0, Loss0.620608539481079\n",
      "Epoch250, w10.9479345029586637, w20.5572104124306078, Bias0, Loss0.6205961018404745\n",
      "Epoch250, w10.9497118288127404, w20.5555562644399157, Bias0, Loss0.6205840471410231\n",
      "Epoch250, w10.9514986257447285, w20.5539623265066372, Bias0, Loss0.6205723397150034\n",
      "Epoch250, w10.9532931841315224, w20.5524245276433357, Bias0, Loss0.6205609487633396\n",
      "Epoch250, w10.9550939288833346, w20.5509390968372013, Bias0, Loss0.6205498476605075\n",
      "Epoch250, w10.9568994095277028, w20.549502541112902, Bias0, Loss0.6205390133584562\n",
      "Epoch250, w10.958708290996163, w20.5481116251452498, Bias0, Loss0.6205284258755903\n",
      "Epoch250, w10.9605193450675187, w20.5467633523205192, Bias0, Loss0.6205180678587905\n",
      "Epoch250, w10.9623314424240926, w20.5454549471505756, Bias0, Loss0.6205079242081166\n",
      "Epoch250, w10.9641435452797591, w20.5441838389492298, Bias0, Loss0.6204979817552984\n",
      "Epoch250, w10.9659547005409185, w20.5429476466853755, Bias0, Loss0.6204882289883534\n",
      "Epoch250, w10.9677640334638661, w20.5417441649324706, Bias0, Loss0.620478655815756\n",
      "Epoch250, w10.9695707417742164, w20.5405713508387527, Bias0, Loss0.6204692533645073\n",
      "Epoch250, w10.9713740902161697, w20.5394273120472309, Bias0, Loss0.6204600138072556\n",
      "Epoch250, w10.9731734055014397, w20.5383102954989434, Bias0, Loss0.6204509302143045\n",
      "Epoch250, w10.974968071629597, w20.5372186770572228, Bias0, Loss0.6204419964269383\n",
      "Epoch250, w10.9767575255534259, w20.5361509518947466, Bias0, Loss0.6204332069490005\n",
      "Epoch250, w10.9785412531646355, w20.5351057255889844, Bias0, Loss0.6204245568541013\n",
      "Epoch250, w10.9803187855769165, w20.5340817058752781, Bias0, Loss0.6204160417062051\n",
      "Epoch250, w10.9820896956848926, w20.5330776950102136, Bias0, Loss0.6204076574916654\n",
      "Epoch250, w10.983853594978979, w20.5320925827011663, Bias0, Loss0.6203994005610614\n",
      "Epoch250, w10.9856101305975422, w20.5311253395609365, Bias0, Loss0.6203912675794183\n",
      "Epoch250, w10.9873589825990451, w20.5301750110492384, Bias0, Loss0.6203832554835992\n",
      "Epoch250, w10.9890998614380759, w20.5292407118654755, Bias0, Loss0.6203753614458359\n",
      "Epoch250, w10.9908325056302961, w20.5283216207597397, Bias0, Loss0.6203675828425069\n",
      "Epoch250, w10.9925566795924006, w20.5274169757313072, Bias0, Loss0.6203599172274067\n",
      "Epoch250, w10.994272171644179, w20.5265260695860948, Bias0, Loss0.620352362308851\n",
      "Epoch250, w10.9959787921606904, w20.5256482458265788, Bias0, Loss0.6203449159300715\n",
      "Epoch250, w10.9976763718634275, w20.5247828948495851, Bias0, Loss0.6203375760524114\n",
      "Epoch250, w10.9993647602401529, w20.523929450429134, Bias0, Loss0.6203303407409293\n",
      "Epoch250, w11.0010438240838357, w20.5230873864631751, Bias0, Loss0.6203232081520511\n",
      "Epoch250, w11.0027134461418188, w20.5222562139645909, Bias0, Loss0.6203161765229789\n",
      "Epoch250, w11.0043735238669897, w20.5214354782782744, Bias0, Loss0.620309244162603\n",
      "Epoch250, w11.0060239682633392, w20.5206247565074236, Bias0, Loss0.6203024094436954\n",
      "Epoch250, w11.0076647028188421, w20.5198236551334277, Bias0, Loss0.6202956707962016\n",
      "Epoch250, w11.0092956625191258, w20.5190318078148738, Bias0, Loss0.6202890267014709\n",
      "Epoch250, w11.0109167929358644, w20.5182488733522681, Bias0, Loss0.6202824756872907\n",
      "Epoch250, w11.0125280493842954, w20.5174745338060576, Bias0, Loss0.620276016323605\n",
      "Epoch250, w11.0141293961446631, w20.5167084927564561, Bias0, Loss0.6202696472188219\n",
      "Epoch250, w11.015720805742784, w20.5159504736944353, Bias0, Loss0.6202633670166239\n",
      "Epoch250, w11.0173022582852853, w20.5152002185340263, Bias0, Loss0.6202571743932039\n",
      "Epoch250, w11.0188737408454003, w20.5144574862368182, Bias0, Loss0.6202510680548755\n",
      "Epoch250, w11.0204352468955094, w20.5137220515402114, Bias0, Loss0.6202450467359918\n",
      "Epoch250, w11.0219867757829033, w20.5129937037816216, Bias0, Loss0.6202391091971365\n",
      "Epoch250, w11.0235283322455082, w20.5122722458114065, Bias0, Loss0.6202332542235459\n",
      "Epoch250, w11.0250599259645539, w20.5115574929878347, Bias0, Loss0.6202274806237266\n",
      "Epoch250, w11.0265815711513957, w20.5108492722479095, Bias0, Loss0.6202217872282452\n",
      "Epoch250, w11.028093286165911, w20.510147421248332, Bias0, Loss0.62021617288866\n",
      "Epoch250, w11.029595093164079, w20.5094517875713085, Bias0, Loss0.6202106364765796\n",
      "Epoch250, w11.0310870177725415, w20.5087622279903127, Bias0, Loss0.6202051768828262\n",
      "Epoch250, w11.0325690887880987, w20.5080786077912745, Bias0, Loss0.6201997930166927\n",
      "Epoch250, w11.0340413379002542, w20.5074008001450108, Bias0, Loss0.6201944838052773\n",
      "Epoch250, w11.0355037994350647, w20.5067286855270284, Bias0, Loss0.6201892481928851\n",
      "Epoch250, w11.0369565101186786, w20.5060621511811194, Bias0, Loss0.6201840851404898\n",
      "Epoch250, w11.0383995088590727, w20.5054010906234396, Bias0, Loss0.6201789936252445\n",
      "Epoch250, w11.0398328365446066, w20.504745403184011, Bias0, Loss0.6201739726400356\n",
      "Epoch250, w11.0412565358581194, w20.5040949935828173, Bias0, Loss0.6201690211930753\n",
      "Epoch250, w11.0426706511053916, w20.5034497715378791, Bias0, Loss0.6201641383075246\n",
      "Epoch250, w11.0440752280568781, w20.5028096514028879, Bias0, Loss0.6201593230211467\n",
      "Epoch250, w11.04547031380171, w20.5021745518321648, Bias0, Loss0.6201545743859828\n",
      "Epoch250, w11.046855956613029, w20.5015443954708756, Bias0, Loss0.62014989146805\n",
      "Epoch250, w11.048232205823797, w20.5009191086685935, Bias0, Loss0.6201452733470577\n",
      "Epoch250, w11.0495991117122823, w20.5002986212144399, Bias0, Loss0.6201407191161399\n",
      "Epoch250, w11.0509567253964902, w20.49968286609217366, Bias0, Loss0.6201362278816015\n",
      "Epoch250, w11.0523050987368545, w20.4990717792537164, Bias0, Loss0.6201317987626781\n",
      "Epoch250, w11.0536442842465639, w20.4984652994097207, Bias0, Loss0.6201274308913057\n",
      "Epoch250, w11.0549743350089416, w20.4978633678358903, Bias0, Loss0.6201231234119007\n",
      "Epoch250, w11.0562953046013424, w20.4972659281938601, Bias0, Loss0.6201188754811483\n",
      "Epoch250, w11.0576072470250688, w20.4966729263655343, Bias0, Loss0.6201146862677994\n",
      "Epoch250, w11.0589102166408506, w20.49608431029986355, Bias0, Loss0.6201105549524734\n",
      "Epoch250, w11.0602042681094621, w20.49550002987112035, Bias0, Loss0.6201064807274679\n",
      "Epoch250, w11.061489456337086, w20.49492003674780144, Bias0, Loss0.6201024627965747\n",
      "Epoch250, w11.0627658364250618, w20.4943442842713535, Bias0, Loss0.6200985003749\n",
      "Epoch250, w11.064033463623685, w20.4937727273439786, Bias0, Loss0.6200945926886887\n",
      "Epoch250, w11.065292393289747, w20.4932053223248316, Bias0, Loss0.6200907389751564\n",
      "Epoch250, w11.06654268084753, w20.49264202693397546, Bias0, Loss0.6200869384823205\n",
      "Epoch250, w11.0677843817529948, w20.4920828001635062, Bias0, Loss0.6200831904688403\n",
      "Epoch250, w11.0690175514609146, w20.4915276021953058, Bias0, Loss0.6200794942038553\n",
      "Epoch250, w11.0702422453947316, w20.4909763943249211, Bias0, Loss0.6200758489668322\n",
      "Epoch250, w11.071458518918927, w20.49042913889110545, Bias0, Loss0.6200722540474101\n",
      "Epoch250, w11.0726664273137125, w20.48988579921059483, Bias0, Loss0.6200687087452521\n",
      "Epoch250, w11.0738660257518653, w20.48934633951772183, Bias0, Loss0.6200652123698988\n",
      "Epoch250, w11.0750573692775414, w20.4888107249085023, Bias0, Loss0.6200617642406221\n",
      "Epoch250, w11.0762405127869163, w20.48827892128885647, Bias0, Loss0.6200583636862862\n",
      "Epoch250, w11.0774155110105124, w20.4877508953266512, Bias0, Loss0.6200550100452059\n",
      "Epoch250, w11.0785824184970831, w20.4872266144072755, Bias0, Loss0.6200517026650121\n",
      "Epoch250, w11.0797412895989345, w20.486706046592481, Bias0, Loss0.6200484409025153\n",
      "Epoch250, w11.0808921784585723, w20.4861891605822425, Bias0, Loss0.6200452241235742\n",
      "Epoch250, w11.0820351389965748, w20.4856759256794082, Bias0, Loss0.6200420517029652\n",
      "Epoch250, w11.0831702249005926, w20.48516631175693103, Bias0, Loss0.6200389230242541\n",
      "Epoch250, w11.0842974896153934, w20.4846602892274845, Bias0, Loss0.6200358374796703\n",
      "Epoch250, w11.0854169863338659, w20.48415782901528426, Bias0, Loss0.6200327944699823\n",
      "Epoch250, w11.0865287679889108, w20.4836589025299482, Bias0, Loss0.6200297934043749\n",
      "Epoch250, w11.087632887246152, w20.4831634816422418, Bias0, Loss0.6200268337003298\n",
      "Epoch250, w11.0887293964973983, w20.4826715386615661, Bias0, Loss0.6200239147835069\n",
      "Epoch250, w11.0898183478548036, w20.48218304631505715, Bias0, Loss0.6200210360876258\n",
      "Epoch250, w11.0908997931456668, w20.4816979777281759, Bias0, Loss0.6200181970543533\n",
      "Epoch250, w11.0919737839078232, w20.48121630640667545, Bias0, Loss0.620015397133188\n",
      "Epoch250, w11.0930403713855796, w20.4807380062198428, Bias0, Loss0.6200126357813496\n",
      "Epoch250, w11.0940996065261517, w20.48026305138491865, Bias0, Loss0.6200099124636689\n",
      "Epoch250, w11.095151539976563, w20.4797914164526069, Bias0, Loss0.6200072266524788\n",
      "Epoch250, w11.0961962220809702, w20.47932307629359217, Bias0, Loss0.6200045778275081\n",
      "Epoch250, w11.097233702878379, w20.478858006085989, Bias0, Loss0.6200019654757762\n",
      "Epoch250, w11.098264032100721, w20.47839618130365363, Bias0, Loss0.6199993890914893\n",
      "Epoch250, w11.0992872591712632, w20.47793757770529305, Bias0, Loss0.6199968481759386\n",
      "Epoch250, w11.10030343320332, w20.47748217132431175, Bias0, Loss0.6199943422373981\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch250, w11.1013126029992486, w20.4770299384593413, Bias0, Loss0.6199918707910281\n",
      "Epoch250, w11.1023148170497006, w20.47658085566540087, Bias0, Loss0.6199894333587752\n",
      "Epoch250, w11.1033101235331102, w20.4761348997456427, Bias0, Loss0.6199870294692769\n",
      "Epoch250, w11.1042985703154005, w20.4756920477436377, Bias0, Loss0.6199846586577661\n",
      "Epoch250, w11.1052802049498884, w20.4752522769361616, Bias0, Loss0.6199823204659783\n",
      "Epoch250, w11.106255074677374, w20.4748155648264445, Bias0, Loss0.6199800144420591\n",
      "Epoch250, w11.1072232264263961, w20.47438188913784846, Bias0, Loss0.6199777401404728\n",
      "Epoch250, w11.1081847068136421, w20.47395122780794263, Bias0, Loss0.6199754971219137\n",
      "Epoch250, w11.1091395621444982, w20.4735235589829453, Bias0, Loss0.6199732849532172\n",
      "Epoch250, w11.1100878384137287, w20.47309886101250637, Bias0, Loss0.6199711032072733\n",
      "Epoch250, w11.111029581306273, w20.4726771124448049, Bias0, Loss0.6199689514629402\n",
      "Epoch250, w11.1119648361981485, w20.4722582920219386, Bias0, Loss0.6199668293049607\n",
      "Epoch250, w11.1128936481574527, w20.47184237867558315, Bias0, Loss0.6199647363238782\n",
      "Epoch250, w11.1138160619454545, w20.4714293515229029, Bias0, Loss0.6199626721159546\n",
      "Epoch250, w11.1147321220177653, w20.47101918986269287, Bias0, Loss0.61996063628309\n",
      "Epoch250, w11.1156418725255852, w20.4706118731717365, Bias0, Loss0.6199586284327427\n",
      "Epoch250, w11.116545357317015, w20.4702073811013623, Bias0, Loss0.6199566481778506\n",
      "Epoch250, w11.1174426199384293, w20.4698056934741862, Bias0, Loss0.6199546951367537\n",
      "Epoch250, w11.118333703635904, w20.46940679028102483, Bias0, Loss0.619952768933117\n",
      "Epoch250, w11.119218651356693, w20.4690106516779682, Bias0, Loss0.6199508691958576\n",
      "Epoch250, w11.1200975057507496, w20.46861725798360004, Bias0, Loss0.6199489955590677\n",
      "Epoch250, w11.120970309172287, w20.46822658967635533, Bias0, Loss0.6199471476619429\n",
      "Epoch250, w11.1218371036813743, w20.467838627392005, Bias0, Loss0.619945325148711\n",
      "Epoch250, w11.1226979310455665, w20.46745335192125886, Bias0, Loss0.6199435276685591\n",
      "Epoch250, w11.1235528327415578, w20.46707074420747846, Bias0, Loss0.6199417548755648\n",
      "Epoch250, w11.124401849956865, w20.46669078534449204, Bias0, Loss0.6199400064286271\n",
      "Epoch250, w11.125245023591529, w20.46631345657450424, Bias0, Loss0.6199382819913984\n",
      "Epoch250, w11.126082394259836, w20.4659387392860943, Bias0, Loss0.6199365812322166\n",
      "Epoch250, w11.1269140022920558, w20.46556661501229657, Bias0, Loss0.6199349038240408\n",
      "Epoch250, w11.1277398877361944, w20.4651970654287569, Bias0, Loss0.6199332494443845\n",
      "Epoch250, w11.1285600903597564, w20.4648300723519611, Bias0, Loss0.6199316177752522\n",
      "Epoch250, w11.1293746496515193, w20.4644656177375292, Bias0, Loss0.6199300085030761\n",
      "Epoch250, w11.1301836048233147, w20.46410368367857185, Bias0, Loss0.6199284213186537\n",
      "Epoch250, w11.1309869948118159, w20.4637442524041045, Bias0, Loss0.619926855917086\n",
      "Epoch250, w11.13178485828033, w20.46338730627751534, Bias0, Loss0.6199253119977175\n",
      "Epoch250, w11.1325772336205944, w20.4630328277950838, Bias0, Loss0.6199237892640758\n",
      "Epoch250, w11.1333641589545729, w20.462680799584546, Bias0, Loss0.6199222874238136\n",
      "Epoch250, w11.1341456721362553, w20.46233120440370423, Bias0, Loss0.6199208061886501\n",
      "Epoch250, w11.1349218107534542, w20.4619840251390775, Bias0, Loss0.6199193452743131\n",
      "Epoch250, w11.1356926121296025, w20.461639244804591, Bias0, Loss0.6199179044004844\n",
      "Epoch250, w11.1364581133255467, w20.46129684654030156, Bias0, Loss0.6199164832907428\n",
      "Epoch250, w11.137218351141338, w20.4609568136111567, Bias0, Loss0.6199150816725094\n",
      "Epoch250, w11.1379733621180204, w20.4606191294057863, Bias0, Loss0.6199136992769944\n",
      "Epoch250, w11.1387231825394117, w20.4602837774353235, Bias0, Loss0.619912335839143\n",
      "Epoch250, w11.1394678484338814, w20.4599507413322541, Bias0, Loss0.6199109910975839\n",
      "Epoch250, w11.1402073955761218, w20.4596200048492925, Bias0, Loss0.6199096647945761\n",
      "Epoch250, w11.1409418594889127, w20.45929155185828235, Bias0, Loss0.6199083566759596\n",
      "Epoch250, w11.1416712754448792, w20.4589653663491212, Bias0, Loss0.6199070664911038\n",
      "Epoch250, w11.142395678468243, w20.4586414324287071, Bias0, Loss0.619905793992859\n",
      "Epoch250, w11.1431151033365636, w20.45831973431990614, Bias0, Loss0.6199045389375067\n",
      "Epoch250, w11.1438295845824749, w20.45800025636054037, Bias0, Loss0.6199033010847116\n",
      "Epoch250, w11.1445391564954095, w20.4576829830023941, Bias0, Loss0.6199020801974746\n",
      "Epoch250, w11.1452438531233176, w20.4573678988102383, Bias0, Loss0.619900876042086\n",
      "Epoch250, w11.1459437082743746, w20.4570549884608722, Bias0, Loss0.6198996883880787\n",
      "Epoch250, w11.1466387555186808, w20.4567442367421806, Bias0, Loss0.6198985170081834\n",
      "Epoch250, w11.1473290281899506, w20.4564356285522069, Bias0, Loss0.6198973616782836\n",
      "Epoch250, w11.1480145593871933, w20.4561291488982405, Bias0, Loss0.619896222177371\n",
      "Epoch250, w11.1486953819763825, w20.4558247828959189, Bias0, Loss0.6198950982875027\n",
      "Epoch250, w11.1493715285921173, w20.4555225157683419, Bias0, Loss0.6198939897937578\n",
      "Epoch250, w11.1500430316392718, w20.45522233284519986, Bias0, Loss0.6198928964841951\n",
      "Epoch250, w11.1507099232946354, w20.4549242195619134, Bias0, Loss0.6198918181498115\n",
      "Epoch250, w11.1513722355085423, w20.45462816145878515, Bias0, Loss0.6198907545845007\n",
      "Epoch250, w11.1520300000064914, w20.4543341441801627, Bias0, Loss0.6198897055850128\n",
      "Epoch250, w11.1526832482907543, w20.4540421534736123, Bias0, Loss0.6198886709509144\n",
      "Epoch250, w11.1533320116419743, w20.45375217518910316, Bias0, Loss0.6198876504845489\n",
      "Epoch250, w11.1539763211207543, w20.45346419527820164, Bias0, Loss0.619886643990998\n",
      "Epoch250, w11.1546162075692332, w20.4531781997932752, Bias0, Loss0.6198856512780428\n",
      "Epoch250, w11.1552517016126533, w20.45289417488670575, Bias0, Loss0.6198846721561273\n",
      "Epoch250, w11.1558828336609162, w20.45261210681011177, Bias0, Loss0.6198837064383196\n",
      "Epoch250, w11.1565096339101275, w20.45233198191357976, Bias0, Loss0.619882753940276\n",
      "Epoch250, w11.1571321323441321, w20.4520537866449035, Bias0, Loss0.6198818144802055\n",
      "Epoch250, w11.1577503587360385, w20.45177750754883195, Bias0, Loss0.6198808878788328\n",
      "Epoch250, w11.1583643426497308, w20.4515031312663253, Bias0, Loss0.619879973959364\n",
      "Epoch250, w11.1589741134413734, w20.4512306445338182, Bias0, Loss0.6198790725474514\n",
      "Epoch250, w11.1595797002609018, w20.45096003418249114, Bias0, Loss0.6198781834711604\n",
      "Epoch250, w11.160181132053505, w20.4506912871375489, Bias0, Loss0.6198773065609341\n",
      "Epoch250, w11.1607784375610959, w20.4504243904175063, Bias0, Loss0.619876441649562\n",
      "Epoch250, w11.1613716453237732, w20.4501593311334809, Bias0, Loss0.6198755885721456\n",
      "Epoch250, w11.16196078368127, w20.44989609648849244, Bias0, Loss0.6198747471660672\n",
      "Epoch250, w11.1625458807743947, w20.44963467377676924, Bias0, Loss0.6198739172709579\n",
      "Epoch250, w11.1631269645464597, w20.4493750503830609, Bias0, Loss0.6198730987286656\n",
      "Epoch250, w11.1637040627447008, w20.44911721378195757, Bias0, Loss0.6198722913832246\n",
      "Epoch250, w11.1642772029216857, w20.44886115153721534, Bias0, Loss0.6198714950808258\n",
      "Epoch250, w11.1648464124367126, w20.4486068513010879, Bias0, Loss0.619870709669785\n",
      "Epoch250, w11.1654117184571988, w20.4483543008136642, Bias0, Loss0.619869935000514\n",
      "Epoch250, w11.1659731479600584, w20.448103487902212, Bias0, Loss0.6198691709254925\n",
      "Epoch250, w11.1665307277330708, w20.4478544004805273, Bias0, Loss0.6198684172992377\n",
      "Epoch250, w11.167084484376239, w20.44760702654828954, Bias0, Loss0.6198676739782765\n",
      "Epoch250, w11.1676344443031368, w20.4473613541904221, Bias0, Loss0.6198669408211177\n",
      "Epoch250, w11.1681806337422487, w20.44711737157645876, Bias0, Loss0.6198662176882241\n",
      "Epoch250, w11.168723078738297, w20.44687506695991525, Bias0, Loss0.6198655044419856\n",
      "Epoch250, w11.1692618051535613, w20.44663442867766656, Bias0, Loss0.619864800946692\n",
      "Epoch250, w11.1697968386691866, w20.446395445149329, Bias0, Loss0.6198641070685068\n",
      "Epoch250, w11.170328204786484, w20.446158104876648, Bias0, Loss0.619863422675441\n",
      "Epoch250, w11.170855928828219, w20.44592239644289045, Bias0, Loss0.6198627476373271\n",
      "Epoch250, w11.171380035939893, w20.44568830851224284, Bias0, Loss0.6198620818257949\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1.171380035939893, 0.44568830851224284, 0)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grediant_descent(x_train_scaled['age'], x_train_scaled['affordibility'],y_train,250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.91673   ],\n",
       "        [0.84574246]], dtype=float32),\n",
       " array([-0.17642361], dtype=float32))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coef,intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "class my_nn:\n",
    "    def __init__(self):\n",
    "        self.w1=1\n",
    "        self.w2=1\n",
    "        self.bias=0\n",
    "    def fit(self,x,y,epochs):\n",
    "        self.w1, self.w2, self.bias =self.grediant_descent(x['age'],x['affordibility'],y,epochs)\n",
    "       \n",
    "    def predict(self,x_test):\n",
    "            weighted_sum = self.w1*x_test['age'] + self.w2*x_test['affordibility'] + self.bias\n",
    "            return sigmoid_numpy(weighted_sum)\n",
    "    def grediant_descent(self,age, affordibility,y_real,epochs):\n",
    "        w1=w2=1 #this is random\n",
    "        bias=0 # this is random\n",
    "        rate=0.5 # this is radom\n",
    "        n= len(age)\n",
    "        for i  in range(epochs):\n",
    "            weighted_sum = w1*age + w2*affordibility +bias\n",
    "            y_predicted = sigmoid_numpy(weighted_sum)\n",
    "            loss= log_loss(y_real,y_predicted)\n",
    "            w1d= (1/n)*np.dot(np.transpose(age),(y_predicted-y_real))\n",
    "            w2d= (1/n)*np.dot(np.transpose(affordibility),(y_predicted-y_real))\n",
    "            bias_d=np.mean(y_predicted-y_real)\n",
    "            w1=w1-rate*w1d\n",
    "            w2=w2-rate*w2d\n",
    "            print(f\"Epoch{epochs}, w1{w1}, w2{w2}, Bias{bias}, Loss{loss}\")\n",
    "        return w1,w2,bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch5, w10.9907935440408127, w20.9718534166129719, Bias0, Loss0.6346629803353081\n",
      "Epoch5, w10.9822988457688695, w20.9453180752475226, Bias0, Loss0.6329607413873718\n",
      "Epoch5, w10.9744842020227098, w20.9203261765063466, Bias0, Loss0.6314547683088135\n",
      "Epoch5, w10.967317663085986, w20.8968090220823797, Bias0, Loss0.6301252485169614\n",
      "Epoch5, w10.9607672897186681, w20.8746976242560986, Bias0, Loss0.6289537979728407\n"
     ]
    }
   ],
   "source": [
    "obj=my_nn()\n",
    "obj.fit(x_train_scaled,y_train,epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.79022103, 0.74032064, 0.56212715, 0.7583606 , 0.79338863,\n",
       "       0.81164975])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obj.predict(x_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.7502942 ],\n",
       "       [0.69726974],\n",
       "       [0.5154766 ],\n",
       "       [0.7162637 ],\n",
       "       [0.7537135 ],\n",
       "       [0.77356017]], dtype=float32)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(x_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
